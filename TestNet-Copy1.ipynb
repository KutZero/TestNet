{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "023e5ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#from sklearn.neural_network import MLPRegressor\n",
    "#from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eeb34ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''MLPRegressor(hidden_layer_sizes=(900,7), activation='relu',\n",
    "             solver='adam',alpha=0.001, \n",
    "             batch_size=13, learning_rate='constant',learning_rate_init=0.001, \n",
    "             max_iter=1000, shuffle=True,random_state=5, tol=0.001, \n",
    "             early_stopping=True,\n",
    "             verbose=True,\n",
    "             validation_fraction=0.2\n",
    "             )'''\n",
    "\n",
    "path_to_data = ('ngp.csv','timesereis_8_2.csv')\n",
    "target = 'price'\n",
    "\n",
    "cur_hidden_layer_sizes = (900,7)\n",
    "cur_act_fun = 'relu'\n",
    "cur_solver = 'adam'\n",
    "cur_alpha = 0.001\n",
    "cur_batch_size = 13\n",
    "cur_learning_rate = 'constant'\n",
    "cur_learning_rate_init = 0.001\n",
    "cur_max_iter = 1000\n",
    "cur_shuffle = True\n",
    "cur_random_state = 5\n",
    "cur_tol = 0.001\n",
    "cur_early_stopping = True\n",
    "cur_verbose = True\n",
    "cur_validation_fraction = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62055c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(path, target_name):\n",
    "    print(\"///////// get_df /////////\")\n",
    "    file = pd.read_csv(path)\n",
    "    dframe = pd.DataFrame(list(reversed(file[target_name])))\n",
    "    print(dframe)\n",
    "    print(\"///////// get_df_end /////////\")\n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca89a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_and_names(df):\n",
    "    input_t = 4\n",
    "    output_t = 1\n",
    "    \n",
    "    cols = list()\n",
    "    names = list()\n",
    "    \n",
    "    print(\"///////// get_cols_and_names /////////\")\n",
    "    for i in range(input_t,0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        #cols.append(np.array(df.shift(i))\n",
    "        print(f\"df.shift({i}).shape: \", df.shift(i).shape, \"type: \", type(df.shift(i)))\n",
    "        names.append(i)\n",
    "    print(\"///////// Next loop /////////\")\n",
    "    for i in range(0,output_t):\n",
    "        #cols.append(np.array(df.shift(-i))\n",
    "        cols.append(df.shift(-i))                    \n",
    "        print(f\"df.shift({-i}).shape: \", df.shift(-i).shape)\n",
    "        names.append(i+input_t+1)\n",
    "        \n",
    "    #print(\"\\ncols.shape: \", np.array(cols).shape)\n",
    "    #print(\"names: \", names)\n",
    "    \n",
    "    #print(\"len(cols)\", len(cols))\n",
    "    #print(\"len(cols[0])\", len(cols[0]))\n",
    "    #print(\"len(cols[0][0])\", len(cols[0][0]))\n",
    "    \n",
    "    #print(\"cols[0][0]: \", cols[0][0])\n",
    "    #print(\"cols[0]: \", cols[0])\n",
    "    \n",
    "    #print(\"Cols: \", cols)\n",
    "    \n",
    "    print(\"///////// get_cols_and_names_end /////////\")\n",
    "    return cols,names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d2fa36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X,Y,factor):\n",
    "    X_train=X[:factor]\n",
    "    Y_train=Y[:factor]\n",
    "    X_test=X[factor:]\n",
    "    Y_test=Y[factor:]\n",
    "    return X_train,Y_train,X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bbd49b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(cols,names):\n",
    "    print(\"///////// prepare_df /////////\")\n",
    "    n_df = pd.concat(cols, axis = 1)\n",
    "    n_df.columns = names\n",
    "    \n",
    "    print(\"n_df: \", n_df)\n",
    "    \n",
    "    n_df.dropna(inplace = True)\n",
    "    \n",
    "    print(\"n_df: \", n_df)\n",
    "    \n",
    "    print(\"///////// prepare_df_end /////////\")\n",
    "    return n_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d86bb2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "def prep_data_4_1_time(cols, names, prepared_df):\n",
    "    print(\"///////// prep_data_4_1_time /////////\")\n",
    " \n",
    "    X = prepared_df[[4, 3, 2, 1]]\n",
    "    Y = prepared_df[5]\n",
    "    X = X / X.max()\n",
    "    #ones = np.ones(shape = (X.shape[0], 1))\n",
    "    #X = np.append(X, ones, axis = 1)\n",
    "    Y = np.asarray(Y)\n",
    "    Y = Y / Y.max()\n",
    "\n",
    "    #print(\"X[0], Y[0]\", X[0], Y[0])\n",
    "    #print(\"X[1], Y[1]\", X[1], Y[1])\n",
    "    \n",
    "    factor = int(.80*X.shape[0])\n",
    "\n",
    "    print(\"///////// prep_data_4_1_time_end /////////\")\n",
    "    return split(X ,Y , factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0972b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep_data_4_1_time()\n",
    "#pd.DataFrame.dropna?\n",
    "#np.asarray?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "746b5cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def prep_data_8_2_time(path):\\n    file = pd.read_csv(path)\\n    \\n    X = file[['0','1','2','3','4','5','6','7']]\\n    X = X / X.max()\\n    Y = file[['8','9']]\\n    Y = Y / Y.max()\\n\\n    ones = np.ones(shape = (X.shape[0], 1))\\n    X = np.append(X, ones, axis=1)\\n    Y = np.asarray(Y)\\n    factor=int(.80 * X.shape[0])\\n\\n    return split(X, Y, factor)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def prep_data_8_2_time(path):\n",
    "    file = pd.read_csv(path)\n",
    "    \n",
    "    X = file[['0','1','2','3','4','5','6','7']]\n",
    "    X = X / X.max()\n",
    "    Y = file[['8','9']]\n",
    "    Y = Y / Y.max()\n",
    "\n",
    "    ones = np.ones(shape = (X.shape[0], 1))\n",
    "    X = np.append(X, ones, axis=1)\n",
    "    Y = np.asarray(Y)\n",
    "    factor=int(.80 * X.shape[0])\n",
    "\n",
    "    return split(X, Y, factor)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3537ab9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"clf=MLPRegressor(\\n    hidden_layer_sizes=(900,7), # 2 скрытых слоя, первый с 900 нейронами, второй с 7 ?\\n    activation='relu', # функция активации скрытых слоев\\n    solver='adam', # метод оптимизации\\n    alpha=0.001, #\\n    batch_size=13, # количество наборов данных, подаваемых в сеть для обучения (1,1,1 -> результат 4), (1,1,2 -> результат 2). \\n    # тогда batch_size = 2\\n    learning_rate='constant', # изменять ли шаг сходимости по мере обучения сети\\n    learning_rate_init=0.001, # начальный шаг  сходимости\\n    max_iter=1000, # макс кол-во итераций на эпоху?\\n    shuffle=True, # перемешивать ли  данный в каждой итерации\\n    random_state=5, # случайная генерация чисел происходит только 1 раз, все последующие разы она не меняется \\n    # для весов и мб биасов\\n    tol=0.001, # минимальное изменение loss для какое-то кол-во итераций (10 по умолчанию), при котором стоит \\n    # продолжать обучение\\n    early_stopping=True, # остановка обучения, если сеть перестала обучаться\\n    verbose=True, # выводить ли в консоль прогресс обучения\\n    validation_fraction = 0.2 # процент данных, отсекаемых для валидационной выборки\\n    )\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''clf=MLPRegressor(\n",
    "    hidden_layer_sizes = cur_hidden_layer_sizes, \n",
    "    activation = cur_act_fun,\n",
    "    solver = cur_solver,\n",
    "    alpha = cur_alpha, \n",
    "    batch_size = cur_batch_size, \n",
    "    learning_rate = cur_learning_rate,\n",
    "    learning_rate_init = cur_learning_rate_init, \n",
    "    max_iter = cur_max_iter, \n",
    "    shuffle = cur_shuffle,\n",
    "    random_state = cur_random_state, \n",
    "    tol = cur_tol, \n",
    "    early_stopping = cur_early_stopping,\n",
    "    verbose=cur_verbose,\n",
    "    validation_fraction=cur_validation_fraction\n",
    "    )'''\n",
    "\n",
    "model = keras.Sequential([Dense(4, activation = 'relu'),\n",
    "                   Dense(900, activation = 'relu'),\n",
    "                   Dense(7, activation = \"relu\"),\n",
    "                   Dense(1, activation = \"linear\")])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam(0.001))\n",
    "\n",
    "'''clf=MLPRegressor(\n",
    "    hidden_layer_sizes=(900,7), # 2 скрытых слоя, первый с 900 нейронами, второй с 7 ?\n",
    "    activation='relu', # функция активации скрытых слоев\n",
    "    solver='adam', # метод оптимизации\n",
    "    alpha=0.001, #\n",
    "    batch_size=13, # количество наборов данных, подаваемых в сеть для обучения (1,1,1 -> результат 4), (1,1,2 -> результат 2). \n",
    "    # тогда batch_size = 2\n",
    "    learning_rate='constant', # изменять ли шаг сходимости по мере обучения сети\n",
    "    learning_rate_init=0.001, # начальный шаг  сходимости\n",
    "    max_iter=1000, # макс кол-во итераций на эпоху?\n",
    "    shuffle=True, # перемешивать ли  данный в каждой итерации\n",
    "    random_state=5, # случайная генерация чисел происходит только 1 раз, все последующие разы она не меняется \n",
    "    # для весов и мб биасов\n",
    "    tol=0.001, # минимальное изменение loss для какое-то кол-во итераций (10 по умолчанию), при котором стоит \n",
    "    # продолжать обучение\n",
    "    early_stopping=True, # остановка обучения, если сеть перестала обучаться\n",
    "    verbose=True, # выводить ли в консоль прогресс обучения\n",
    "    validation_fraction = 0.2 # процент данных, отсекаемых для валидационной выборки\n",
    "    )'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6072cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLPRegressor?\n",
    "keras.Sequential.compile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12d39bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "///////// get_df /////////\n",
      "         0\n",
      "0     3.79\n",
      "1     4.19\n",
      "2     2.98\n",
      "3     2.91\n",
      "4     2.53\n",
      "...    ...\n",
      "1077  2.93\n",
      "1078  2.91\n",
      "1079  2.96\n",
      "1080  3.09\n",
      "1081  2.96\n",
      "\n",
      "[1082 rows x 1 columns]\n",
      "///////// get_df_end /////////\n",
      "///////// get_cols_and_names /////////\n",
      "df.shift(4).shape:  (1082, 1) type:  <class 'pandas.core.frame.DataFrame'>\n",
      "df.shift(3).shape:  (1082, 1) type:  <class 'pandas.core.frame.DataFrame'>\n",
      "df.shift(2).shape:  (1082, 1) type:  <class 'pandas.core.frame.DataFrame'>\n",
      "df.shift(1).shape:  (1082, 1) type:  <class 'pandas.core.frame.DataFrame'>\n",
      "///////// Next loop /////////\n",
      "df.shift(0).shape:  (1082, 1)\n",
      "///////// get_cols_and_names_end /////////\n",
      "///////// prepare_df /////////\n",
      "n_df:           4     3     2     1     5\n",
      "0      NaN   NaN   NaN   NaN  3.79\n",
      "1      NaN   NaN   NaN  3.79  4.19\n",
      "2      NaN   NaN  3.79  4.19  2.98\n",
      "3      NaN  3.79  4.19  2.98  2.91\n",
      "4     3.79  4.19  2.98  2.91  2.53\n",
      "...    ...   ...   ...   ...   ...\n",
      "1077  2.80  2.85  2.95  2.97  2.93\n",
      "1078  2.85  2.95  2.97  2.93  2.91\n",
      "1079  2.95  2.97  2.93  2.91  2.96\n",
      "1080  2.97  2.93  2.91  2.96  3.09\n",
      "1081  2.93  2.91  2.96  3.09  2.96\n",
      "\n",
      "[1082 rows x 5 columns]\n",
      "n_df:           4     3     2     1     5\n",
      "4     3.79  4.19  2.98  2.91  2.53\n",
      "5     4.19  2.98  2.91  2.53  2.30\n",
      "6     2.98  2.91  2.53  2.30  1.91\n",
      "7     2.91  2.53  2.30  1.91  1.82\n",
      "8     2.53  2.30  1.91  1.82  1.86\n",
      "...    ...   ...   ...   ...   ...\n",
      "1077  2.80  2.85  2.95  2.97  2.93\n",
      "1078  2.85  2.95  2.97  2.93  2.91\n",
      "1079  2.95  2.97  2.93  2.91  2.96\n",
      "1080  2.97  2.93  2.91  2.96  3.09\n",
      "1081  2.93  2.91  2.96  3.09  2.96\n",
      "\n",
      "[1073 rows x 5 columns]\n",
      "///////// prepare_df_end /////////\n",
      "///////// prep_data_4_1_time /////////\n",
      "///////// prep_data_4_1_time_end /////////\n"
     ]
    }
   ],
   "source": [
    "df = get_df(path_to_data[0], target)\n",
    "cols, names = get_cols_and_names(df)\n",
    "#print(df)\n",
    "prepared_df = prepare_df(cols,names)\n",
    "prepared_data = prep_data_4_1_time(cols,names,prepared_df)\n",
    "\n",
    "X_train,Y_train,X_test,Y_test = prepared_data\n",
    "#train the model\n",
    "#clf.fit(X_train,Y_train)\n",
    "#score of the model\n",
    "#print(\"score of first model\",clf.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26b44883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0358 - val_loss: 0.0084\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size = 13, epochs = 1, verbose = True, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1e53de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 571us/step - loss: 0.0125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.012525551952421665"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model\n",
    "#pred = clf.predict(X_test)\n",
    "#print(\"error of first model\",mean_squared_error(Y_test,pred))\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2620de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train,Y_train,X_test,Y_test=prep_data_8_2_time(path_to_data[1])\\n#train the model\\nclf.fit(X_train,Y_train)\\n#score of the model\\nprint(\"score of second model\",clf.score(X_test,Y_test));'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''X_train,Y_train,X_test,Y_test=prep_data_8_2_time(path_to_data[1])\n",
    "#train the model\n",
    "clf.fit(X_train,Y_train)\n",
    "#score of the model\n",
    "print(\"score of second model\",clf.score(X_test,Y_test));'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "484eae40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#test the model\\npred = clf.predict(X_test)\\nprint(\"error of second model\",mean_squared_error(Y_test,pred))'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#test the model\n",
    "pred = clf.predict(X_test)\n",
    "print(\"error of second model\",mean_squared_error(Y_test,pred))'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
