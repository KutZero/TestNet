{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0661cf17",
   "metadata": {},
   "source": [
    "# Последняя версия LSTM сети, обучающаяся на большом наборе данных\n",
    "## Есть train и test ноутбуки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ae7a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from IPython.display import display\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Dropout, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69a60d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# детерминация случайных величин, отвечающих за выбор первоначальных весов и биасов\n",
    "tf.compat.v1.set_random_seed(290)\n",
    "tf.random.set_seed(290)\n",
    "np.random.seed(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff10edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#///////////////////////////////// для работы с датасетом\n",
    "\n",
    "    # путь к файлу, из которого берутся данные для обучения\n",
    "path_to_positive_data = 'positive.csv' \n",
    "path_to_negative_data = 'negative.csv'\n",
    "\n",
    "    # куда сохранять данные после обработки (вытащит один столбец, убрал англ. символы)\n",
    "path_to_processed_positive_data = \"my_pos_text.csv\" \n",
    "path_to_processed_negative_data = \"my_neg_text.csv\"\n",
    "\n",
    "    # название взятой величины из файла\n",
    "target = 'text' \n",
    "\n",
    "#///////////////////////////////// для колбэков\n",
    "\n",
    "    # для Early_stopping\n",
    "ES_patience = 20 # кол-во эпох без улучшений\n",
    "ES_min_delta = 0.001 # минимальное улучшение параметра за cur_patience\n",
    "ES_monitor_parametr =  'val_loss' # отслеживаемый параметр \n",
    "ES_save_best_weights = True # сохранять ли веса нейронки с лучшими результатами\n",
    "    \n",
    "    # для ReduceLROnPlateau\n",
    "RLPOP_monitor_parametr = 'loss'  # отслеживаемый параметр \n",
    "RLPOP_factor = 0.1 # множитель для расчета нового шага сходимости (new_learning_rate = old_learning_rate*RLPOP_factor)\n",
    "RLPOP_patience = 15 # кол-во эпох без улучшений\n",
    "RLPOP_verbose = 1 # выводить ли прогресс изменения шага сходимости в его процессее\n",
    "RLPOP_mode = 'auto' # выбирает, уменьшать шаг сходимости при росте величины или при её уменьшении\n",
    "RLPOP_min_delta = 0.0001 # порог изменения отслеживаемого значения\n",
    "RLPOP_cooldown = 0 # количество эпох до возобновления работы после изменения шага сходимости\n",
    "RLPOP_min_lr = 0 # минимальное значение шага сходимости\n",
    "\n",
    "    # для CallbackList\n",
    "CBL_add_history = True # вызывать ли колбэк History (если он не был довавлен вручную)\n",
    "CBL_add_progbar = True # вызывать ли колбэк ProgbarLogger (если он не был довавлен вручную)\n",
    "\n",
    "    #///////////////////////////////// для работы со словами\n",
    "    \n",
    "maxWordsCount = 6000 # макс слов в словаре\n",
    "max_text_len = 10 # макс длинна высказывания\n",
    "\n",
    "    #///////////////////////////////// для компиляции \n",
    "    \n",
    "CMP_learning_rate = 0.2 # шаг сходимости back propogation\n",
    "CMP_solver = tf.keras.optimizers.SGD(learning_rate = CMP_learning_rate, momentum = 0.8, nesterov = True) # оптимизатор\n",
    "CMP_loss_func = 'binary_crossentropy' # функция потерь\n",
    "CMP_metrics = ['accuracy'] # отслеживаемые метрики\n",
    "\n",
    "#///////////////////////////////// для тренировки\n",
    "\n",
    "FIT_batch_size = 800 # размер батчей\n",
    "FIT_shuffle = True # перемешивать ли данные\n",
    "FIT_verbose = 1 # выводить ли прогресс обучения в его процессее\n",
    "FIT_epochs = 100 # количество эпох обучения\n",
    "FIT_validation_split = 0.15 # процент валидационных данных, отсекаемых из тестовой выборки\n",
    "FIT_steps_per_epoch = 3000 # кол-во шагов в эпоху (не используется)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa63867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделить данные на тренировочные и тестовые\n",
    "def split(X,Y,factor):\n",
    "    X_train=X[:factor]\n",
    "    Y_train=Y[:factor]\n",
    "    X_test=X[factor:]\n",
    "    Y_test=Y[factor:]\n",
    "    return X_train,Y_train,X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad4068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# извлечь датасет из файла\n",
    "def get_df(path, target_name = '2', serarator = ',', col_names = ['1','2']):\n",
    "    \n",
    "    file = pd.read_csv(path, sep = serarator, names = col_names)\n",
    "    dframe = pd.DataFrame(file[target_name])\n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e392bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# убрать англ символы из всех строк датасета\n",
    "def remove_english(df):\n",
    "    temp = list()\n",
    "    for index, row in df.iterrows():\n",
    "        temp.append(\"\".join([w for w in row[target] if not re.match(r'[A-Z]+', w, re.I)]))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eb60335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_text:  ['@_ хоть я и школота, но поверь, у нас то же самое : общество профилирующий предмет типа)'\n",
      " 'Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:'\n",
      " ' @: Ну ты идиотка) я испугалась за тебя!!!'\n",
      " ' @2912: \"Кто то в углу сидит и погибает от голода, а мы ещё 2 порции взяли, хотя уже и так жрать не хотим\" : ://./62…'\n",
      " '@_ Вот что значит страшилка :\\nНо блин,посмотрев все части,у тебя создастся ощущение,что авторы курили что-то :'] \n",
      "\n",
      "neg_text:  ['на работе был полный пиддес :| и так каждое закрытие месяца, я же свихнусь так :'\n",
      " 'Коллеги сидят рубятся в  , а я из-за долбанной винды не могу :('\n",
      " '@_4 как говорят обещаного три года ждут...(('\n",
      " 'Желаю хорошего полёта и удачной посадки,я буду очень сильно скучать( ://./3'\n",
      " 'Обновил за каким-то лешим , теперь не работает простоплеер :(']\n"
     ]
    }
   ],
   "source": [
    "temp_names = [\"id\",\"name\",\"text\",\"her1\",\"her2\",\"her3\",\n",
    "                  \"her4\",\"her5\",\"her6\",\"her7\",\"her8\"] # названия колонок для ориг датасета \n",
    "\n",
    "# если оригинальный датасет не обрабатывался - обработать и создать новый\n",
    "if not os.path.exists(path_to_processed_positive_data):\n",
    "    pos_df = get_df(path_to_positive_data, target, \";\", temp_names) # вытащит данные из определенногог столбца с опр сепаратором\n",
    "    \n",
    "    pos_text = remove_english(pos_df)\n",
    "    pos_df = pd.DataFrame(pos_text)\n",
    "    \n",
    "    # сохранить как csv (чтобы каждый раз не делать долгую обработку)\n",
    "    pos_df.to_csv(path_to_processed_positive_data, header = False)\n",
    "else:\n",
    "    pos_df = get_df(path_to_processed_positive_data) # вытащит данные из единственного столбца\n",
    "    pos_text = pos_df['2'].values.tolist()\n",
    "    \n",
    "# если оригинальный датасет не обрабатывался - обработать и создать новый    \n",
    "if not os.path.exists(path_to_processed_negative_data):\n",
    "    neg_df = get_df(path_to_negative_data, target, \";\", temp_names) # вытащит данные из определенногог столбца с опр сепаратором\n",
    "    \n",
    "    neg_text = remove_english(neg_df)\n",
    "    neg_df = pd.DataFrame(neg_text)\n",
    "    \n",
    "    # сохранить как csv (чтобы каждый раз не делать долгую обработку)\n",
    "    neg_df.to_csv(path_to_processed_negative_data, header = False) \n",
    "else:\n",
    "    neg_df = get_df(path_to_processed_negative_data) # вытащит данные из единственного столбца\n",
    "    neg_text = neg_df['2'].values.tolist()\n",
    "\n",
    "    \n",
    "print(\"pos_text: \", np.array(pos_text[:5]), \"\\n\")\n",
    "print(\"neg_text: \", np.array(neg_text[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84790ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_text_num:  114911 \n",
      "neg_text_num:  111923 \n",
      "all_text_num:  226834\n"
     ]
    }
   ],
   "source": [
    "# создание списка из всех выражений\n",
    "texts = pos_text + neg_text\n",
    "count_true = len(pos_text)\n",
    "count_false = len(neg_text)\n",
    "total_lines = count_true + count_false\n",
    "print(\n",
    "    \"pos_text_num: \", count_true, \n",
    "    \"\\nneg_text_num: \", count_false,\n",
    "    \"\\nall_text_num: \", total_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c37b6a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226834,) (226834,)\n",
      "indeces:  [ 48642 208321  32328 ... 198974  69071 119132] \n",
      "\n",
      "train:  (181467,) (181467,) <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "test:  (45367,) (45367,) <class 'numpy.ndarray'> <class 'numpy.ndarray'> \n",
      "\n",
      "Планшет шалит. Перемещает картинки из одной папки в другую. У меня фото Уэя в фартучке в папке с котятами. Хотя стойте, все правильно: 1\n",
      "мои съёмки постоянно куда то переносятся.\n",
      "я когда нибудь отщелкаю пленку? Мю:( 0\n",
      " @_: Ну поймёт только лучшая подруга :) 1\n",
      "@ @ бизнес с друзьями заводить нельзя :( 0\n",
      " @_: Настя подари мне щастья подари мне радость подари любовь :\n",
      "Азазаза 1\n"
     ]
    }
   ],
   "source": [
    "# создание тренировочной/тестовой выборок\n",
    "X_data = np.array(texts)\n",
    "\n",
    "Y_data = np.array([1]*count_true + [0]*count_false)\n",
    "print(X_data.shape, Y_data.shape)\n",
    "\n",
    "# создание массива индексов чтобы перемешать данные\n",
    "indeces = np.random.choice(X_data.shape[0], size = X_data.shape[0], replace=False)\n",
    "\n",
    "print(\"indeces: \", indeces, \"\\n\")\n",
    "\n",
    "# перемешивание данных\n",
    "X_data = X_data[indeces]\n",
    "Y_data = Y_data[indeces]\n",
    "\n",
    "# соотношение тренировочной выборки к тестовой\n",
    "factor = int(.80 * X_data.shape[0])\n",
    "\n",
    "X_train,Y_train,X_test,Y_test = split(X_data,Y_data,factor)\n",
    "\n",
    "print(\"train: \", X_train.shape, Y_train.shape, type(X_train), type(Y_train))\n",
    "print(\"test: \", X_test.shape, Y_test.shape, type(X_test), type(Y_test), \"\\n\")\n",
    "\n",
    "for x in range(5):\n",
    "    print(X_train[x], Y_train[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba7032d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential model с преобработкой\n",
    "model = keras.models.load_model(\"EmotionRecognition_LSTM_NetWork\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "821d2e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maybe[Позитивно] [0.7062]  ==  Right[Позитивно]\t @ никаких колебаний))) все ровно))) на бум бум,значит на бум бум)))\n",
      "Maybe[Позитивно] [0.8802]      Right[Негативно]\t @ ой, а кстати, как твое творчество там поживает хоть? Очень скучаю за твоими работами :(\n",
      "Maybe[Позитивно] [0.7511]  ==  Right[Позитивно]\t @2584 @ @ @_ @_ спасибо:3 и тебе добра))\n",
      "Maybe[Негативно] [0.4417]      Right[Позитивно]\t Жвачка Орбит — укрепляет не только зубы, но и парты в школе) ://./3\n",
      "Maybe[Позитивно] [0.6695]  ==  Right[Позитивно]\t Добрый день) / Как ваш понедельник? ://./3\n",
      "Maybe[Негативно] [0.4943]      Right[Позитивно]\t вообщем что хотела сделать придя домой,так и не сделала)\n",
      "_______________\n",
      "в этом вся Я:\n",
      "Maybe[Позитивно] [0.5973]  ==  Right[Позитивно]\t \"Это платье на мне плохо сидит\" - \"Да,на фото как-то кривовато\".Да,Тань?)\n",
      "Maybe[Негативно] [0.1990]  ==  Right[Негативно]\t Ну вот опять начался тот период когда всем насрать на тебя(\n",
      "Maybe[Негативно] [0.0442]  ==  Right[Негативно]\t ибо мне хреново:( #\n",
      "Maybe[Негативно] [0.1730]  ==  Right[Негативно]\t наверное грустно там работать  @: \"МАЗ останавливает работу\". что-то мне это напоминает(\n"
     ]
    }
   ],
   "source": [
    "# вывести пару результатов работы\n",
    "for x in range(10,20):    \n",
    "    a = np.array([X_test[x]])\n",
    "    \n",
    "    res = model.predict(a)  \n",
    "    mark = \"Позитивно\" if np.mean(res) > 0.5 else \"Негативно\"\n",
    "    mark2 = \"Позитивно\" if Y_test[x] == 1 else \"Негативно\"\n",
    "    equal = \"==\" if mark == mark2 else \"  \"\n",
    "    \n",
    "    print((f\"Maybe[{mark}] [%.4f] \" % np.mean(res)) , equal , f\" Right[{mark2}]\\t\" , X_test[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b287f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 1s 12ms/step - loss: 0.5689 - accuracy: 0.6978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5689471364021301, 0.6977759003639221]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# тест модели\n",
    "model.evaluate(X_test, Y_test, batch_size = FIT_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bffa550f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mark [отрицательно]\n",
      "res:  [[0.41758302]]\n",
      "res[0,0]:  0.41758302\n"
     ]
    }
   ],
   "source": [
    "# подать строку в модель\n",
    "t = \"хохлы люди\"\n",
    "\n",
    "a = list()\n",
    "a.append(t)\n",
    "a = np.array(a)\n",
    "\n",
    "res = model.predict(a)\n",
    "\n",
    "mark = \"Положительно\" if np.mean(res) > 0.5 else \"отрицательно\"\n",
    "\n",
    "print(f\"mark [{mark}]\")\n",
    "print(\"res: \", res)\n",
    "print(\"res[0,0]: \", res[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f051385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mark [отрицательно]\n",
      "res:  [[0.0390704]]\n",
      "res[0,0]:  0.039070398\n"
     ]
    }
   ],
   "source": [
    "# подать строку в модель\n",
    "t = \"это просто ужасно плохо противно не хорошо\"\n",
    "\n",
    "a = list()\n",
    "a.append(t)\n",
    "a = np.array(a)\n",
    "\n",
    "res = model.predict(a)\n",
    "\n",
    "mark = \"Положительно\" if np.mean(res) > 0.5 else \"отрицательно\"\n",
    "\n",
    "print(f\"mark [{mark}]\")\n",
    "print(\"res: \", res)\n",
    "print(\"res[0,0]: \", res[0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
