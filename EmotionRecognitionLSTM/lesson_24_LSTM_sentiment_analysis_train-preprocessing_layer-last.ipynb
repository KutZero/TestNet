{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ae7a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from IPython.display import display\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Dropout, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69a60d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# детерминация случайных величин, отвечающих за выбор первоначальных весов и биасов\n",
    "tf.compat.v1.set_random_seed(290)\n",
    "tf.random.set_seed(290)\n",
    "np.random.seed(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f8f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_positive_data = 'positive.csv' # путь к файлу, из которого берутся данные для обучения\n",
    "path_to_negative_data = 'negative.csv'\n",
    "\n",
    "path_to_processed_positive_data = \"my_pos_text.csv\"\n",
    "path_to_processed_negative_data = \"my_neg_text.csv\"\n",
    "\n",
    "target = 'text' # название взятой величины из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff10edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#///////////////////////////////// для колбэков\n",
    "\n",
    "    # для Early_stopping\n",
    "ES_patience = 20 # кол-во эпох без улучшений\n",
    "ES_min_delta = 0.001 # минимальное улучшение параметра за cur_patience\n",
    "ES_monitor_parametr =  'val_loss' # отслеживаемый параметр \n",
    "ES_save_best_weights = True # сохранять ли веса нейронки с лучшими результатами\n",
    "    \n",
    "    # для ReduceLROnPlateau\n",
    "RLPOP_monitor_parametr = 'loss'  # отслеживаемый параметр \n",
    "RLPOP_factor = 0.1 # множитель для расчета нового шага сходимости (new_learning_rate = old_learning_rate*RLPOP_factor)\n",
    "RLPOP_patience = 15 # кол-во эпох без улучшений\n",
    "RLPOP_verbose = 1 # выводить ли прогресс изменения шага сходимости в его процессее\n",
    "RLPOP_mode = 'auto' # выбирает, уменьшать шаг сходимости при росте величины или при её уменьшении\n",
    "RLPOP_min_delta = 0.0001 # порог изменения отслеживаемого значения\n",
    "RLPOP_cooldown = 0 # количество эпох до возобновления работы после изменения шага сходимости\n",
    "RLPOP_min_lr = 0 # минимальное значение шага сходимости\n",
    "\n",
    "    # для CallbackList\n",
    "CBL_add_history = True # вызывать ли колбэк History (если он не был довавлен вручную)\n",
    "CBL_add_progbar = True # вызывать ли колбэк ProgbarLogger (если он не был довавлен вручную)\n",
    "    \n",
    "maxWordsCount = 6000 #15000\n",
    "max_text_len = 10\n",
    "FIT_batch_size = 800 #1200 #1600 #1000 #250 #400 #500 #500 #10 #8 #15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aa63867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделить данные на тренировочные и тестовые\n",
    "def split(X,Y,factor):\n",
    "    X_train=X[:factor]\n",
    "    Y_train=Y[:factor]\n",
    "    X_test=X[factor:]\n",
    "    Y_test=Y[factor:]\n",
    "    return X_train,Y_train,X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad4068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# извлечь датасет из файла\n",
    "def get_df(path, target_name = '2', serarator = ',', col_names = ['1','2']):\n",
    "    \n",
    "    file = pd.read_csv(path, sep = serarator, names = col_names)\n",
    "    dframe = pd.DataFrame(file[target_name])\n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e392bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_english(df):\n",
    "    temp = list()\n",
    "    for index, row in df.iterrows():\n",
    "        temp.append(\"\".join([w for w in row[target] if not re.match(r'[A-Z]+', w, re.I)]))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eb60335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_text:  ['@_ хоть я и школота, но поверь, у нас то же самое : общество профилирующий предмет типа)'\n",
      " 'Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:'\n",
      " ' @: Ну ты идиотка) я испугалась за тебя!!!'\n",
      " ' @2912: \"Кто то в углу сидит и погибает от голода, а мы ещё 2 порции взяли, хотя уже и так жрать не хотим\" : ://./62…'\n",
      " '@_ Вот что значит страшилка :\\r\\nНо блин,посмотрев все части,у тебя создастся ощущение,что авторы курили что-то :'\n",
      " 'ну любишь или нет? — Я не знаю кто ты бля: ://./916'\n",
      " ' @: Ох,900 : ну это конечно же @ . Чтобы у нее было много друзей, ведь она такая мимими &;3'\n",
      " ' @: У тебя есть ухажёр? Нет - мои уши не кто не жрёт :'\n",
      " 'Поприветствуем моего нового читателя @1789 ;)'\n",
      " 'Теперь у меня есть частичка Сиднея :) # # ://./3']\n",
      "neg_text:  ['на работе был полный пиддес :| и так каждое закрытие месяца, я же свихнусь так :'\n",
      " 'Коллеги сидят рубятся в  , а я из-за долбанной винды не могу :('\n",
      " '@_4 как говорят обещаного три года ждут...(('\n",
      " 'Желаю хорошего полёта и удачной посадки,я буду очень сильно скучать( ://./3'\n",
      " 'Обновил за каким-то лешим , теперь не работает простоплеер :('\n",
      " 'Котёнка вчера носик разбила, плакала и расстраивалась :('\n",
      " '@ @_55 @_ Зашли, а то он опять затихарился, я прямо физически страдаю, когда он долго молчит!((('\n",
      " 'а вообще я не болею -  я не выздоравливаю :('\n",
      " 'я микрофраза :( учимся срать кирпичами в режиме &;;нон-стоп&;; @'\n",
      " 'я хочу с тобой помириться , но сука я гордая и никогда этого не сделаю! (((']\n"
     ]
    }
   ],
   "source": [
    "# если оригинальный датасет не обрабатывался - обработать и создать новый\n",
    "temp_names = [\"id\",\"name\",\"text\",\"her1\",\"her2\",\"her3\",\n",
    "                  \"her4\",\"her5\",\"her6\",\"her7\",\"her8\"] # названия колонок для ориг датасета \n",
    "\n",
    "if not os.path.exists(path_to_processed_positive_data):\n",
    "    pos_df = get_df(path_to_positive_data, target, \";\", temp_names)\n",
    "    \n",
    "    pos_text = remove_english(pos_df)\n",
    "    pos_df = pd.DataFrame(pos_text)\n",
    "    \n",
    "    pos_df.to_csv(path_to_processed_positive_data, header = False)\n",
    "else:\n",
    "    pos_df = get_df(path_to_processed_positive_data)\n",
    "    pos_text = pos_df['2'].values.tolist()\n",
    "    \n",
    "# если оригинальный датасет не обрабатывался - обработать и создать новый    \n",
    "if not os.path.exists(path_to_processed_negative_data):\n",
    "    neg_df = get_df(path_to_negative_data, target, \";\", temp_names)\n",
    "    \n",
    "    neg_text = remove_english(neg_df)\n",
    "    neg_df = pd.DataFrame(neg_text)\n",
    "    \n",
    "    neg_df.to_csv(path_to_processed_negative_data, header = False)\n",
    "else:\n",
    "    neg_df = get_df(path_to_processed_negative_data)\n",
    "    neg_text = neg_df['2'].values.tolist()\n",
    "\n",
    "print(\"pos_text: \", np.array(pos_text[:10]))\n",
    "print(\"neg_text: \", np.array(neg_text[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84790ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_text_num:  114911 \n",
      "neg_text_num:  111923 \n",
      "all_text_num:  226834\n"
     ]
    }
   ],
   "source": [
    "texts = pos_text + neg_text\n",
    "count_true = len(pos_text)\n",
    "count_false = len(neg_text)\n",
    "total_lines = count_true + count_false\n",
    "print(\n",
    "    \"pos_text_num: \", count_true, \n",
    "    \"\\nneg_text_num: \", count_false,\n",
    "    \"\\nall_text_num: \", total_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c37b6a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226834,) (226834,)\n",
      "indeces:  [ 48642 208321  32328 ... 198974  69071 119132]\n",
      "train:  (181467,) (181467,) <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "test:  (45367,) (45367,) <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Планшет шалит. Перемещает картинки из одной папки в другую. У меня фото Уэя в фартучке в папке с котятами. Хотя стойте, все правильно: 1\n",
      "мои съёмки постоянно куда то переносятся.\n",
      "я когда нибудь отщелкаю пленку? Мю:( 0\n",
      " @_: Ну поймёт только лучшая подруга :) 1\n",
      "@ @ бизнес с друзьями заводить нельзя :( 0\n",
      " @_: Настя подари мне щастья подари мне радость подари любовь :\n",
      "Азазаза 1\n"
     ]
    }
   ],
   "source": [
    "X_data = np.array(texts)\n",
    "\n",
    "Y_data = np.array([1]*count_true + [0]*count_false)\n",
    "print(X_data.shape, Y_data.shape)\n",
    "\n",
    "indeces = np.random.choice(X_data.shape[0], size = X_data.shape[0], replace=False)\n",
    "\n",
    "print(\"indeces: \", indeces)\n",
    "\n",
    "X_data = X_data[indeces]\n",
    "Y_data = Y_data[indeces]\n",
    "\n",
    "factor = int(.80 * X_data.shape[0])\n",
    "\n",
    "X_train,Y_train,X_test,Y_test = split(X_data,Y_data,factor)\n",
    "\n",
    "print(\"train: \", X_train.shape, Y_train.shape, type(X_train), type(Y_train))\n",
    "print(\"test: \", X_test.shape, Y_test.shape, type(X_test), type(Y_test))\n",
    "\n",
    "for x in range(5):\n",
    "    print(X_train[x], Y_train[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "690603d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X.shape)\n",
    "#LSTM?\n",
    "#Sequential.compile?\n",
    "#equential.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba7032d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 10, 64)            384000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 10, 64)            33024     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                5184      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 422,225\n",
      "Trainable params: 422,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Sequential model с преобработкой\n",
    "vectproc = tf.keras.layers.experimental.preprocessing.TextVectorization( #tf.keras.layers.TextVectorization(\n",
    "    max_tokens = maxWordsCount, \n",
    "    standardize = 'lower_and_strip_punctuation',\n",
    "    split = 'whitespace',\n",
    "    output_mode = 'int',\n",
    "    output_sequence_length = max_text_len,\n",
    "    )\n",
    "\n",
    "text_dataset = tf.data.Dataset.from_tensor_slices(texts)\n",
    "\n",
    "vectproc.adapt(text_dataset.batch(64))\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(Input(shape=(1,), dtype=tf.string))\n",
    "model.add(vectproc)\n",
    "model.add(Embedding(maxWordsCount, output_dim = 64, input_length = max_text_len)) #128\n",
    "#model.add(LSTM(units = 128, return_sequences = True, dropout = 0.3))\n",
    "model.add(LSTM(units = 64, return_sequences = True, dropout = 0.3))\n",
    "model.add(LSTM(units = 16, dropout = 0.3))\n",
    "model.add(Dense(units = 1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc68b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание и настройка колбэков\n",
    "callback_list = [] # массив колбэков до подачи в колбек \"callbacklist\"\n",
    "\n",
    "temp = keras.callbacks.EarlyStopping(\n",
    "            monitor = ES_monitor_parametr, \n",
    "            min_delta = ES_min_delta, \n",
    "            patience = ES_patience,\n",
    "            restore_best_weights = ES_save_best_weights\n",
    "            )\n",
    "callback_list.append(temp)\n",
    "\n",
    "temp = keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor = RLPOP_monitor_parametr, \n",
    "            factor = RLPOP_factor, \n",
    "            patience = RLPOP_patience, \n",
    "            verbose = RLPOP_verbose,\n",
    "            mode = RLPOP_mode, \n",
    "            min_delta = RLPOP_min_delta, \n",
    "            cooldown = RLPOP_cooldown, \n",
    "            min_lr = RLPOP_min_lr\n",
    "            )\n",
    "callback_list.append(temp)\n",
    "\n",
    "FIT_callback_list = keras.callbacks.CallbackList(\n",
    "            callbacks = callback_list, \n",
    "            add_history = CBL_add_history, \n",
    "            add_progbar = CBL_add_progbar, \n",
    "            model = model\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "030a85bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',#'mean_squared_error', \n",
    "              metrics=['accuracy'], \n",
    "              # learning_rate = 0.1\n",
    "              optimizer = tf.keras.optimizers.SGD(learning_rate = 0.2, momentum = 0.8, nesterov = True)) #0.1))#0.08))\n",
    "#tf.keras.optimizers.SGD(learning_rate = 0.01)) #0.01\n",
    "# tf.keras.optimizers.SGD(learning_rate = 0.0001)) #0.05)) #Adam(0.0003)) #'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4936374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.models.Sequential.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e55503e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 15s 78ms/step - loss: 0.6855 - accuracy: 0.5496 - val_loss: 0.6759 - val_accuracy: 0.5794\n",
      "193/193 [==============================] - 14s 74ms/step - loss: 0.6674 - accuracy: 0.5955 - val_loss: 0.6539 - val_accuracy: 0.6153\n",
      "193/193 [==============================] - 14s 73ms/step - loss: 0.6482 - accuracy: 0.6228 - val_loss: 0.6318 - val_accuracy: 0.6426\n",
      "193/193 [==============================] - 14s 73ms/step - loss: 0.6367 - accuracy: 0.6382 - val_loss: 0.6312 - val_accuracy: 0.6368\n",
      "193/193 [==============================] - 14s 72ms/step - loss: 0.6237 - accuracy: 0.6510 - val_loss: 0.6230 - val_accuracy: 0.6465\n",
      "193/193 [==============================] - 14s 75ms/step - loss: 0.6147 - accuracy: 0.6608 - val_loss: 0.6415 - val_accuracy: 0.6287\n",
      "193/193 [==============================] - 14s 74ms/step - loss: 0.6080 - accuracy: 0.6675 - val_loss: 0.5999 - val_accuracy: 0.6761\n",
      "106/193 [===============>..............] - ETA: 6s - loss: 0.5989 - accuracy: 0.6730"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ILYIN~1.EVG\\AppData\\Local\\Temp/ipykernel_13992/1658303257.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(X_train, \n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFIT_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\NETwork\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\NETwork\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\NETwork\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\NETwork\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\NETwork\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\NETwork\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\NETwork\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\NETwork\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\NETwork\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                    Y_train, \n",
    "                    batch_size = FIT_batch_size, \n",
    "                    shuffle = True, \n",
    "                    verbose = 1, \n",
    "                    epochs = 30, #100, #30, \n",
    "                    validation_split = 0.15,\n",
    "                    #steps_per_epoch = 3000,\n",
    "                    callbacks = FIT_callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b795f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db8e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d2e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(20): \n",
    "    \n",
    "    a = np.array([X_test[x]])\n",
    "    \n",
    "    #print(a)\n",
    "    \n",
    "    res = model.predict(a)  \n",
    "    \n",
    "    #print(res) \n",
    "    \n",
    "    mark = \"Положительно\" if np.mean(res) > 0.5 else \"Отрицательно\"\n",
    "    mark2 = \"Положительно\" if Y_test[x] == 1 else \"Отрицательно\"\n",
    "    equal = \"==\" if mark == mark2 else \"  \"\n",
    "    \n",
    "    print((f\"Maybe[{mark}] [%.4f] \" % np.mean(res)) , equal , f\" Right[{mark2}]\\t\" , X_test[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65071adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод графика изменения ошибки\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b287f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# тест модели\n",
    "model.evaluate(X_test, Y_test, batch_size = FIT_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19348a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод графика изменения ошибки\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"если вы просто посмотрите на жизнь позитивно произойдут позитивные вещи\"\n",
    "\n",
    "a = list()\n",
    "a.append(t)\n",
    "a = np.array(a)\n",
    "\n",
    "#res = model.predict(data_pad)\n",
    "res = model.predict(a)\n",
    "\n",
    "mark = \"Положительно\" if np.mean(res) > 0.5 else \"отрицательно\"\n",
    "\n",
    "print(f\"mark [{mark}]\")\n",
    "print(\"res: \", res)\n",
    "print(\"res[0,0]: \", res[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f051385",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"это просто ужасно плохо противно не хорошо\"\n",
    "\n",
    "a = list()\n",
    "a.append(t)\n",
    "a = np.array(a)\n",
    "\n",
    "#res = model.predict(data_pad)\n",
    "res = model.predict(a)\n",
    "\n",
    "mark = \"Положительно\" if np.mean(res) > 0.5 else \"отрицательно\"\n",
    "\n",
    "print(f\"mark [{mark}]\")\n",
    "print(\"res: \", res)\n",
    "print(\"res[0,0]: \", res[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe2ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
